{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Mandatory Kaggle Stuff","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/finalproject/__results__.html\n/kaggle/input/finalproject/__notebook__.ipynb\n/kaggle/input/finalproject/__output__.json\n/kaggle/input/finalproject/custom.css\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport scipy\nfrom scipy import signal\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\npd.set_option('display.max_colwidth', 500)\n","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Importing train data\ndf = pd.read_csv('../input/digit-recognizer/train.csv')","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Creating X & Y for Train_test_split\nX = df.drop([\"label\"], axis=1)\nY = df[\"label\"]","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Making filters","metadata":{}},{"cell_type":"code","source":"filter9 = np.array([[1 for x in range(9)] for y in range(9)])\nfilter7 = np.array([[1 for x in range(7)] for y in range(7)])\nfilter5 = np.array([[1 for x in range(5)] for y in range(5)])\n\nfilter9inc = np.array([[1,1,1,1,1,1,1,1,1],\n                      [1,2,2,2,2,2,2,2,1],\n                      [1,2,3,3,3,3,3,2,1],\n                      [1,2,3,4,4,4,3,2,1],\n                      [1,2,3,4,5,4,3,2,1],\n                      [1,2,3,4,4,4,3,2,1],\n                      [1,2,3,3,3,3,3,2,1],\n                      [1,2,2,2,2,2,2,2,1],\n                      [1,1,1,1,1,1,1,1,1]])\n\nfilter7inc = np.array([[1,1,1,1,1,1,1],\n                      [1,2,2,2,2,2,1],\n                      [1,2,3,3,3,2,1],\n                      [1,2,3,4,3,2,1],\n                      [1,2,3,3,3,2,1],\n                      [1,2,2,2,2,2,1],\n                      [1,1,1,1,1,1,1]])\n\nfilter5inc = np.array([[1,1,1,1,1],\n                      [1,2,2,2,1],\n                      [1,2,3,2,1],\n                      [1,2,2,2,1],\n                      [1,1,1,1,1]])","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(filter9.shape,filter9inc.shape)\nprint(filter7.shape,filter7inc.shape)\nprint(filter5.shape,filter5inc.shape)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(9, 9) (9, 9)\n(7, 7) (7, 7)\n(5, 5) (5, 5)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Applying Convolutions using 6 filters","metadata":{}},{"cell_type":"markdown","source":"### 5x5 Filters","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter5, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter5x5simple.csv\")","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(42000, 576)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter5inc, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter5x5inc.csv\")","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(42000, 576)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 7x7 Filters","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter7, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter7x7simple.csv\")","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(42000, 484)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter7inc, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter7x7inc.csv\")","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(42000, 484)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 9x9 Filters","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter9, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter9x9.csv\")","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(42000, 400)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame()\narr = np.asarray(X)\nfor i in range(0,42000):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter9inc, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==30000 or i==40000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"10000\n20000\n30000\n40000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cheking the data shape and Saving the data\nprint(df.shape)\nprint(Y.shape)\ndf.to_csv(\"./filter9x9inc.csv\")","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(42000, 400)\n(42000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Now using the New(Convoluted) Datasets","metadata":{}},{"cell_type":"code","source":"#Importing the dataset and deleting the extra column\ndf = pd.read_csv('../input/digit-recognizer/train.csv')\ndf5=pd.read_csv('./filter5x5simple.csv')\ndel df5['Unnamed: 0']\ndf5inc=pd.read_csv('./filter5x5inc.csv')\ndel df5inc['Unnamed: 0']\ndf7=pd.read_csv('./filter7x7simple.csv')\ndel df7['Unnamed: 0']\ndf7inc=pd.read_csv('./filter7x7inc.csv')\ndel df7inc['Unnamed: 0']\ndf9=pd.read_csv('./filter9x9.csv')\ndel df9['Unnamed: 0']\ndf9inc=pd.read_csv('./filter9x9inc.csv')\ndel df9inc['Unnamed: 0']\n#making the dataframe for accuracy\ndfacc=pd.DataFrame(columns=[\"FilterSize\",\"Model Used\",\"Accuracy\"])\n","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#method to insert acc in dataframe\ndef insertAcc(dff,filters,model,acc):\n    lst=[filters,model,acc]\n    dff.loc[len(dff)] = lst","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Methods To be used on all 6 Datasets","metadata":{}},{"cell_type":"code","source":"y = df[\"label\"]\ndef predOnDf(dataf,y,fSzie,dfacc):\n    X = dataf #Creating X for Train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42) #spliting\n    # ***************************** Multinomial NB *****************************\n    mnb = MultinomialNB()\n    mnb.fit(X_train, y_train)\n    mnbYPred = mnb.predict(X_test)\n    mnbAcc = metrics.accuracy_score(y_test, mnbYPred)\n    print (\"Naive Bayes Accuracy: \", mnbAcc*100)\n    insertAcc(dfacc,fSzie,\"Naive Bayes\",mnbAcc*100) #inserting accuracy into dataframe\n    # ***************************** SVM *****************************\n    svmModel = SVC(kernel=\"rbf\", random_state=42, verbose=True,C=9)\n    svmModel.fit(X_train, y_train)\n    svmYpred = svmModel.predict(X_test)\n    svmAcc = metrics.accuracy_score(y_test,svmYpred)\n    print('SVM Accuracy: ', svmAcc*100)\n    insertAcc(dfacc,fSzie,\"SVM\",svmAcc*100) #inserting accuracy into dataframe\n    # ***************************** Linear Regression *****************************\n    reg = LinearRegression()\n    reg.fit(X_train, y_train)\n    regYpred = reg.predict(X_test)\n    regAcc = metrics.r2_score(y_test,regYpred) \n    print('Linear Regression Accuracy: ', regAcc*100)\n    insertAcc(dfacc,fSzie,\"Linear Regression\",regAcc*100)#inserting accuracy into dataframe\n    # *****************************  KNN *****************************\n    KNNmodel = KNeighborsClassifier()\n    KNNmodel.fit(X_train, y_train)\n    knnYpred = KNNmodel.predict(X_test)\n    knnAcc = metrics.accuracy_score(y_test, knnYpred)\n    print('KNN Accuracy: ',knnAcc*100)\n    insertAcc(dfacc,fSzie,\"KNN\",knnAcc*100)#inserting accuracy into dataframe\n    print(dfacc)","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Making Predictions","metadata":{}},{"cell_type":"markdown","source":"### For 5x5 Datasets","metadata":{}},{"cell_type":"code","source":"predOnDf(df5,y,\"5x5simple\",dfacc)","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  76.14285714285714\n[LibSVM]SVM Accuracy:  97.90476190476191\nLinear Regression Accuracy:  60.54374415007434\nKNN Accuracy:  96.61904761904762\n  FilterSize         Model Used   Accuracy\n0  5x5simple        Naive Bayes  76.142857\n1  5x5simple                SVM  97.904762\n2  5x5simple  Linear Regression  60.543744\n3  5x5simple                KNN  96.619048\n","output_type":"stream"}]},{"cell_type":"code","source":"predOnDf(df5inc,y,\"5x5inc\",dfacc)","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  77.14285714285715\n[LibSVM]SVM Accuracy:  98.11904761904762\nLinear Regression Accuracy:  60.76247887043299\nKNN Accuracy:  96.78571428571429\n  FilterSize         Model Used   Accuracy\n0  5x5simple        Naive Bayes  76.142857\n1  5x5simple                SVM  97.904762\n2  5x5simple  Linear Regression  60.543744\n3  5x5simple                KNN  96.619048\n4     5x5inc        Naive Bayes  77.142857\n5     5x5inc                SVM  98.119048\n6     5x5inc  Linear Regression  60.762479\n7     5x5inc                KNN  96.785714\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### For 7x7 Datasets","metadata":{}},{"cell_type":"code","source":"predOnDf(df7,y,\"7x7simple\",dfacc)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  71.02380952380952\n[LibSVM]SVM Accuracy:  97.4047619047619\nLinear Regression Accuracy:  60.49792885212695\nKNN Accuracy:  94.88095238095238\n   FilterSize         Model Used   Accuracy\n0   5x5simple        Naive Bayes  76.142857\n1   5x5simple                SVM  97.904762\n2   5x5simple  Linear Regression  60.543744\n3   5x5simple                KNN  96.619048\n4      5x5inc        Naive Bayes  77.142857\n5      5x5inc                SVM  98.119048\n6      5x5inc  Linear Regression  60.762479\n7      5x5inc                KNN  96.785714\n8   7x7simple        Naive Bayes  71.023810\n9   7x7simple                SVM  97.404762\n10  7x7simple  Linear Regression  60.497929\n11  7x7simple                KNN  94.880952\n","output_type":"stream"}]},{"cell_type":"code","source":"predOnDf(df7inc,y,\"7x7inc\",dfacc)","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  73.33333333333333\n[LibSVM]SVM Accuracy:  97.73809523809524\nLinear Regression Accuracy:  60.60312330604967\nKNN Accuracy:  95.88095238095238\n   FilterSize         Model Used   Accuracy\n0   5x5simple        Naive Bayes  76.142857\n1   5x5simple                SVM  97.904762\n2   5x5simple  Linear Regression  60.543744\n3   5x5simple                KNN  96.619048\n4      5x5inc        Naive Bayes  77.142857\n5      5x5inc                SVM  98.119048\n6      5x5inc  Linear Regression  60.762479\n7      5x5inc                KNN  96.785714\n8   7x7simple        Naive Bayes  71.023810\n9   7x7simple                SVM  97.404762\n10  7x7simple  Linear Regression  60.497929\n11  7x7simple                KNN  94.880952\n12     7x7inc        Naive Bayes  73.333333\n13     7x7inc                SVM  97.738095\n14     7x7inc  Linear Regression  60.603123\n15     7x7inc                KNN  95.880952\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### For 9x9 Dataset","metadata":{}},{"cell_type":"code","source":"predOnDf(df9,y,\"9x9simple\",dfacc)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  67.23809523809524\n[LibSVM]SVM Accuracy:  96.30952380952381\nLinear Regression Accuracy:  -154707922974569.12\nKNN Accuracy:  92.54761904761905\n   FilterSize         Model Used      Accuracy\n0   5x5simple        Naive Bayes  7.614286e+01\n1   5x5simple                SVM  9.790476e+01\n2   5x5simple  Linear Regression  6.054374e+01\n3   5x5simple                KNN  9.661905e+01\n4      5x5inc        Naive Bayes  7.714286e+01\n5      5x5inc                SVM  9.811905e+01\n6      5x5inc  Linear Regression  6.076248e+01\n7      5x5inc                KNN  9.678571e+01\n8   7x7simple        Naive Bayes  7.102381e+01\n9   7x7simple                SVM  9.740476e+01\n10  7x7simple  Linear Regression  6.049793e+01\n11  7x7simple                KNN  9.488095e+01\n12     7x7inc        Naive Bayes  7.333333e+01\n13     7x7inc                SVM  9.773810e+01\n14     7x7inc  Linear Regression  6.060312e+01\n15     7x7inc                KNN  9.588095e+01\n16  9x9simple        Naive Bayes  6.723810e+01\n17  9x9simple                SVM  9.630952e+01\n18  9x9simple  Linear Regression -1.547079e+14\n19  9x9simple                KNN  9.254762e+01\n","output_type":"stream"}]},{"cell_type":"code","source":"predOnDf(df9inc,y,\"9x9inc\",dfacc)","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy:  70.38095238095238\n[LibSVM]SVM Accuracy:  97.14285714285714\nLinear Regression Accuracy:  60.35209906710299\nKNN Accuracy:  94.35714285714286\n   FilterSize         Model Used      Accuracy\n0   5x5simple        Naive Bayes  7.614286e+01\n1   5x5simple                SVM  9.790476e+01\n2   5x5simple  Linear Regression  6.054374e+01\n3   5x5simple                KNN  9.661905e+01\n4      5x5inc        Naive Bayes  7.714286e+01\n5      5x5inc                SVM  9.811905e+01\n6      5x5inc  Linear Regression  6.076248e+01\n7      5x5inc                KNN  9.678571e+01\n8   7x7simple        Naive Bayes  7.102381e+01\n9   7x7simple                SVM  9.740476e+01\n10  7x7simple  Linear Regression  6.049793e+01\n11  7x7simple                KNN  9.488095e+01\n12     7x7inc        Naive Bayes  7.333333e+01\n13     7x7inc                SVM  9.773810e+01\n14     7x7inc  Linear Regression  6.060312e+01\n15     7x7inc                KNN  9.588095e+01\n16  9x9simple        Naive Bayes  6.723810e+01\n17  9x9simple                SVM  9.630952e+01\n18  9x9simple  Linear Regression -1.547079e+14\n19  9x9simple                KNN  9.254762e+01\n20     9x9inc        Naive Bayes  7.038095e+01\n21     9x9inc                SVM  9.714286e+01\n22     9x9inc  Linear Regression  6.035210e+01\n23     9x9inc                KNN  9.435714e+01\n","output_type":"stream"}]},{"cell_type":"code","source":"#checking Which combination has the highest Accuracy\n#dfacc.columns\ndfacc.sort_values('Accuracy',ascending=False)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   FilterSize         Model Used      Accuracy\n5      5x5inc                SVM  9.811905e+01\n1   5x5simple                SVM  9.790476e+01\n13     7x7inc                SVM  9.773810e+01\n9   7x7simple                SVM  9.740476e+01\n21     9x9inc                SVM  9.714286e+01\n7      5x5inc                KNN  9.678571e+01\n3   5x5simple                KNN  9.661905e+01\n17  9x9simple                SVM  9.630952e+01\n15     7x7inc                KNN  9.588095e+01\n11  7x7simple                KNN  9.488095e+01\n23     9x9inc                KNN  9.435714e+01\n19  9x9simple                KNN  9.254762e+01\n4      5x5inc        Naive Bayes  7.714286e+01\n0   5x5simple        Naive Bayes  7.614286e+01\n12     7x7inc        Naive Bayes  7.333333e+01\n8   7x7simple        Naive Bayes  7.102381e+01\n20     9x9inc        Naive Bayes  7.038095e+01\n16  9x9simple        Naive Bayes  6.723810e+01\n6      5x5inc  Linear Regression  6.076248e+01\n14     7x7inc  Linear Regression  6.060312e+01\n2   5x5simple  Linear Regression  6.054374e+01\n10  7x7simple  Linear Regression  6.049793e+01\n22     9x9inc  Linear Regression  6.035210e+01\n18  9x9simple  Linear Regression -1.547079e+14","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FilterSize</th>\n      <th>Model Used</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>5x5inc</td>\n      <td>SVM</td>\n      <td>9.811905e+01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5x5simple</td>\n      <td>SVM</td>\n      <td>9.790476e+01</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7x7inc</td>\n      <td>SVM</td>\n      <td>9.773810e+01</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7x7simple</td>\n      <td>SVM</td>\n      <td>9.740476e+01</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>9x9inc</td>\n      <td>SVM</td>\n      <td>9.714286e+01</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5x5inc</td>\n      <td>KNN</td>\n      <td>9.678571e+01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5x5simple</td>\n      <td>KNN</td>\n      <td>9.661905e+01</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>9x9simple</td>\n      <td>SVM</td>\n      <td>9.630952e+01</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>7x7inc</td>\n      <td>KNN</td>\n      <td>9.588095e+01</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>7x7simple</td>\n      <td>KNN</td>\n      <td>9.488095e+01</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>9x9inc</td>\n      <td>KNN</td>\n      <td>9.435714e+01</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9x9simple</td>\n      <td>KNN</td>\n      <td>9.254762e+01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5x5inc</td>\n      <td>Naive Bayes</td>\n      <td>7.714286e+01</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5x5simple</td>\n      <td>Naive Bayes</td>\n      <td>7.614286e+01</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>7x7inc</td>\n      <td>Naive Bayes</td>\n      <td>7.333333e+01</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7x7simple</td>\n      <td>Naive Bayes</td>\n      <td>7.102381e+01</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>9x9inc</td>\n      <td>Naive Bayes</td>\n      <td>7.038095e+01</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9x9simple</td>\n      <td>Naive Bayes</td>\n      <td>6.723810e+01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5x5inc</td>\n      <td>Linear Regression</td>\n      <td>6.076248e+01</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7x7inc</td>\n      <td>Linear Regression</td>\n      <td>6.060312e+01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5x5simple</td>\n      <td>Linear Regression</td>\n      <td>6.054374e+01</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>7x7simple</td>\n      <td>Linear Regression</td>\n      <td>6.049793e+01</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>9x9inc</td>\n      <td>Linear Regression</td>\n      <td>6.035210e+01</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>9x9simple</td>\n      <td>Linear Regression</td>\n      <td>-1.547079e+14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Highest Accurcy: 98.11% (Svm,5x5inc)","metadata":{}},{"cell_type":"markdown","source":"### Training the model for final Predictions","metadata":{}},{"cell_type":"code","source":"X = df5inc #Creating X for Train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42) #spliting\n# ***************************** SVM *****************************\nsvmModel = SVC(kernel=\"rbf\", random_state=42, verbose=True,C=9)\nsvmModel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[LibSVM]","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"SVC(C=9, random_state=42, verbose=True)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Reducing the features with the same filter as used for training","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv(\"../input/digit-recognizer/test.csv\")\ndf=pd.DataFrame()\narr = np.asarray(test)\nfor i in range(len(test)):  #Looping through Every row\n    x = None  #Nullifying the variables for every iteration\n    ax = None\n    xRes = None\n    array_1d = None\n    \n    xRes = np.reshape(arr[i],(-1,28))  #reshaping the data to image size\n    x = scipy.signal.convolve2d(xRes, filter5inc, mode='valid') #Applying convolution with one of the two Filters \n    if i == 10000 or i==20000 or i==5000 or i==15000 or i==25000:     # Printing the iteration value to check the progress\n        print(i)\n    ax = x\n    array_1d = ax.flatten()   #flattening the convolve data to 1d array\n    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) #appending it to the new dataframe","metadata":{"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"5000\n10000\n15000\n20000\n25000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Making Predictions And saving the file","metadata":{}},{"cell_type":"code","source":"svmFinalpred=svmModel.predict(df)\nfinalPred=pd.DataFrame(svmFinalpred,columns=[\"Label\"])\nfinalPred['ImageId']=finalPred.index+1\nfinalPred = finalPred.reindex(['ImageId','Label'], axis=1)\nfinalPred.to_csv('./submition.csv',index=False)","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Finally I got 0.98082 Score on Kaggle.","metadata":{}}]}